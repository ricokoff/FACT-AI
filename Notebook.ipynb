{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Review of Self-Explaining Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: *Rico Mossinkoff, Yke Rusticus, Roberto Schiavone, Ewoud Vermeij*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6172/6172 [00:04<00:00, 1341.79it/s]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from api.parameters import RegLambda, HType, NConcepts\n",
    "from api.models import load_compas, load_mnist\n",
    "\n",
    "from api import accuracy, explicitness, faithfulness, stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "For the MNIST dataset, it is possible to load various models specifying the following parameters to the `load_mnist` function:\n",
    "- `h_type=HType.INPUT` and `reg_lambda`\n",
    "- `h_type=HType.CNN`, `reg_lambda` and `n_concepts`\n",
    "\n",
    "If `load_mnist` is called with `h_type=HType.INPUT` and `n_concepts`, `n_concepts` is safely ignored.\n",
    "\n",
    "The default parameters for MNIST are `h_type=HType.INPUT`, `n_concepts=NConcepts.FIVE` and `reg_lambda=RegLambda.E4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPAS\n",
    "\n",
    "For the COMPAS dataset, the only parameter that is possible to specify is the `reg_lambda` coefficient. The default `reg_lambda` value is `RegLambda.E4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available values for each possible parameter are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_type possible values:\n",
      "HType.CNN\n",
      "HType.INPUT\n"
     ]
    }
   ],
   "source": [
    "print('h_type possible values:')\n",
    "for x in HType:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_lambda possible values:\n",
      "RegLambda.ZERO: 0\n",
      "RegLambda.E4: 1e-04\n",
      "RegLambda.E3: 1e-03\n",
      "RegLambda.E2: 1e-02\n",
      "RegLambda.E1: 1e-01\n",
      "RegLambda.ONE: 1\n"
     ]
    }
   ],
   "source": [
    "print('reg_lambda possible values:')\n",
    "for x in RegLambda:\n",
    "    value = ('{:0.0e}' if x.value != 0 and x.value != 1 else '{}').format(x.value)\n",
    "    print(str(x) + ': ' + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_concepts possible values:\n",
      "NConcepts.FIVE: 5\n",
      "NConcepts.TWENTY: 20\n"
     ]
    }
   ],
   "source": [
    "print('n_concepts possible values:')\n",
    "for x in NConcepts:\n",
    "    print(str(x) + ': ' + str(x.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegLambda.ZERO\n",
      "RegLambda.E4\n",
      "RegLambda.E3\n",
      "RegLambda.E2\n",
      "RegLambda.E1\n",
      "RegLambda.ONE\n"
     ]
    }
   ],
   "source": [
    "for x in RegLambda:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model dictionaries for each model configuration\n",
    "compas_models = {}\n",
    "mnist_input_models = {}\n",
    "mnist_cnn_5concepts_models = {}\n",
    "mnist_cnn_20concepts_models = {}\n",
    "\n",
    "for l in RegLambda:\n",
    "    compas_models[l.name] = load_compas(reg_lambda=l, show_specs=False)\n",
    "    mnist_input_models[l.name] = load_mnist(reg_lambda=l, h_type=HType.INPUT, show_specs=False)\n",
    "    mnist_cnn_5concepts_models[l.name] = load_mnist(reg_lambda=l, show_specs=False)\n",
    "    mnist_cnn_20concepts_models[l.name] = load_mnist(reg_lambda=l, n_concepts=NConcepts.TWENTY, show_specs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Below all accuracies of all different model configurations can be found. All accuracies are on par with the accuracies of the original paper, except for the ones using $\\lambda = 1$. Here a for us unexplainable drop in performance is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create accuracy dictionaries for each model configuration (takes ~2min)\n",
    "compas_accuracy = {}\n",
    "mnist_input_accuracy = {}\n",
    "mnist_cnn_5concepts_accuracy = {}\n",
    "mnist_cnn_20concepts_accuracy = {}\n",
    "\n",
    "for l in RegLambda:\n",
    "    compas_accuracy[l.name] = accuracy.evaluate_compas(compas_models[l.name])\n",
    "    mnist_input_accuracy[l.name] = accuracy.evaluate_mnist(mnist_input_models[l.name])\n",
    "    mnist_cnn_5concepts_accuracy[l.name] = accuracy.evaluate_mnist(mnist_cnn_5concepts_models[l.name])\n",
    "    mnist_cnn_20concepts_accuracy[l.name] = accuracy.evaluate_mnist(mnist_cnn_20concepts_models[l.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [compas_accuracy, mnist_input_accuracy, mnist_cnn_5concepts_accuracy, mnist_cnn_20concepts_accuracy]\n",
    "titles = [\"COMPAS\", \"MNIST Input\", \"MNIST CNN 5 Concepts\", \"MNIST CNN 20 Concepts\"]\n",
    "accuracy.plot_accuracy_comparison(accuracies, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitness/Intelligibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explainability plot shows a sample image from the MNIST datset on the left, the relevance scores produced by $\\theta(x)$ in the middle and the prototypes of each basic concepts on the right. The idea is that high relevance score for a certain concept should indicate similarity between the sample image and the prototypes of that image. For our models, this is often not the case. Different models can be used in this function, including different setting for the number of prototypes and layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "explicitness.plot_digit_activation_concept_grid(mnist_cnn_5concepts_models['E1'], index, layout='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension - Synthetic images instead of prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extension to the original paper, we defined a function that searches for image settings activating the concepts most, attempting to produces human interpretable concepts. Unfortunately, the synthetic images are not very human interpretable. Different settings are applied to visualize the synthetic images.\n",
    "\n",
    "$\\alpha$ is a regularization term pushing other concepts to 0 to a certain extend, making the current concept more strongly visible.\n",
    "\n",
    "$\\beta$ is a regularization term able to reduce the noise, as shown in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypes = explicitness.visualize_concepts(mnist_cnn_5concepts_models['E1'],\n",
    "                                             p1=[0,0,1],\n",
    "                                             p2=[0,1,1],\n",
    "                                             method=[\"zero\"] * 3,\n",
    "                                             x0=None,\n",
    "                                             show_loss=False,\n",
    "                                             print_freqs=[0, 0],\n",
    "                                             show_activations=True,\n",
    "                                             return_prototypes=True,\n",
    "                                             best_of=1,\n",
    "                                             compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The faithfullness of the concept describe how important the contribution of each concept is. In other words, what happens if we take one concept and remove. Below we can see a MNIST sample and the relevance score plotted per concept, indicated by the blue bars. In orange, The probability drop when the concept is removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 36\n",
    "faithfulness.plot_faithfulness(mnist_cnn_20concepts_models['E1'], index, show_h=False, show_htheta=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the original paper describe a tradeoff between the model performance and the regularization strength on $\\theta(x)$. The higher the regularization, the more linear (and therefor explanable) the model gets, the lower the predictive performance becomes. And vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability.plot_lipschitz_accuracy(models=list(compas_models.values()), \n",
    "                                  reg_lambdas=[l for l in RegLambda],\n",
    "                                  accuracies=list(compas_accuracy.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the model keeps it local linearity, small changes/perturbations should not have great influence on the relevance scores produced by $\\theta(x)$. As shown below, for a regularized model the small perturbations have no influence on the relevance scores. Unregularized however, shows quite some difference in the relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 18\n",
    "model = mnist_cnn_5concepts_models[RegLambda.E1.name]\n",
    "unregularized_model = mnist_cnn_5concepts_models[RegLambda.ZERO.name]\n",
    "stability.plot_digit_noise_activation_regularized_unregularized(model, unregularized_model, index, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As similar to the MNIST models, we applied a small change in the inputs to determine of the model is not influenced by it. In two settings we change the ethnicity from african american to other. It is shown that of the regularized model the relevance scores stay relatively the same, while the unregularized model is showing some differences. This can also contribute to the fairness of an algorithm, since ethnicity should not have ahuge impact on the recidivism scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    0.,   # Two_yr_Recidivism\n",
    "    0.23, # Number_of_Priors\n",
    "    0.,   # Age_Above_FourtyFive\n",
    "    1.,   # Age_Below_TwentyFive\n",
    "    1.,   # African_American\n",
    "    0.,   # Asian\n",
    "    0.,   # Hispanic\n",
    "    0.,   # Native_American\n",
    "    0.,   # Other\n",
    "    0.,   # Female\n",
    "    0.,   # Misdemeanor\n",
    "    ]\n",
    "\n",
    "y = [\n",
    "    0.,   # Two_yr_Recidivism\n",
    "    0.23, # Number_of_Priors\n",
    "    0.,   # Age_Above_FourtyFive\n",
    "    1.,   # Age_Below_TwentyFive\n",
    "    0.,   # African_American\n",
    "    0.,   # Asian\n",
    "    0.,   # Hispanic\n",
    "    0.,   # Native_American\n",
    "    1.,   # Other\n",
    "    0.,   # Female\n",
    "    0.,   # Misdemeanor\n",
    "    ]\n",
    "\n",
    "model = compas_models[RegLambda.E1.name]\n",
    "unregularized_model = compas_models[RegLambda.ZERO.name]\n",
    "stability.plot_input_values_regularized_unregularized_explanation(model, unregularized_model, [x, y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SENN",
   "language": "python",
   "name": "senn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}